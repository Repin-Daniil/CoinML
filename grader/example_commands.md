# ğŸ“š ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Coin Grader

## ğŸ“ Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹

### 1. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ğ¼Ğ¸ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
```bash
python train.py
```

### 2. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ ĞºĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸ĞµĞ¹
```bash
python train.py --config experiments/config_mobilenet.yaml
```

### 3. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²ĞµÑĞ°Ğ¼Ğ¸
```bash
python train.py --pretrained --config experiments/config_finetune.yaml
```

---

## ğŸ”¬ Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°Ğ¼Ğ¸

### ResNet50 (Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°)
```yaml
# config_resnet.yaml
model:
  backbone_name: "ResNet50"
  dropout_rate: 0.5
  dense_units: 256

training:
  batch_size: 32
  learning_rate: 0.001
```

```bash
python train.py --config config_resnet.yaml
```

### MobileNetV2 (Ğ»ĞµĞ³ĞºĞ¾Ğ²ĞµÑĞ½Ğ°Ñ)
```yaml
# config_mobilenet.yaml
model:
  backbone_name: "MobileNetV2"
  dropout_rate: 0.4
  dense_units: 128

training:
  batch_size: 64
  learning_rate: 0.0005
```

```bash
python train.py --config config_mobilenet.yaml
```

### SimpleCNN (Ñ Ğ½ÑƒĞ»Ñ)
```yaml
# config_simple.yaml
model:
  backbone_name: "SimpleCNN"
  dropout_rate: 0.3
  dense_units: 256

training:
  batch_size: 32
  learning_rate: 0.001
```

```bash
python train.py --config config_simple.yaml
```

---

## ğŸ¨ Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸ĞµĞ¹

### Ğ¡Ğ»Ğ°Ğ±Ğ°Ñ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
```yaml
# config_weak_aug.yaml
augmentation:
  flip_mode: "horizontal"
  rotation_factor: 0.05
  brightness_factor: 0.1
  zoom_factor: 0.05
```

### Ğ¡Ğ¸Ğ»ÑŒĞ½Ğ°Ñ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
```yaml
# config_strong_aug.yaml
augmentation:
  flip_mode: "horizontal_and_vertical"
  rotation_factor: 0.2
  brightness_factor: 0.3
  zoom_factor: 0.15
```

---

## ğŸ“Š ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ³Ğ¸Ğ¿ĞµÑ€Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²

### Ğ’Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ Learning Rate (Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ¹ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸)
```yaml
training:
  learning_rate: 0.01
  lr_scheduler_factor: 0.5
  lr_scheduler_patience: 2
```

### ĞĞ¸Ğ·ĞºĞ¸Ğ¹ Learning Rate (Ğ´Ğ»Ñ fine-tuning)
```yaml
training:
  learning_rate: 0.0001
  lr_scheduler_factor: 0.1
  lr_scheduler_patience: 5
```

### Ğ‘Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ Batch Size (Ğ´Ğ»Ñ A100)
```yaml
training:
  batch_size: 128  # Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ ~40GB VRAM
```

### ĞœĞ°Ğ»ĞµĞ½ÑŒĞºĞ¸Ğ¹ Batch Size (Ğ´Ğ»Ñ CPU/Ğ¼Ğ°Ğ»Ğ¾Ğ³Ğ¾ GPU)
```yaml
training:
  batch_size: 8
```

---

## ğŸ” ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ

### ĞĞ´Ğ½Ğ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ°
```bash
python predict.py \
    --model saved_models/run_resnet50_best.h5 \
    --obverse dataset/test/coin001_obverse.jpg \
    --reverse dataset/test/coin001_reverse.jpg
```

### Batch Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ (Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ evaluate.py)
```bash
python evaluate.py \
    --model saved_models/run_resnet50_best.h5 \
    --config config.yaml
```

---

## ğŸ“ˆ WandB Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ

### Ğ—Ğ°Ğ¿ÑƒÑĞº Ñ ĞºĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğ¼ Ğ¸Ğ¼ĞµĞ½ĞµĞ¼ Ğ² WandB
```yaml
# config.yaml
wandb:
  project_name: "CoinGrader-Experiments"
  run_name: "resnet50_strong_aug_lr001"
```

### Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
```bash
# Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ 1: ResNet50
python train.py --config exp1_resnet.yaml

# Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ 2: MobileNet
python train.py --config exp2_mobilenet.yaml

# Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ 3: SimpleCNN
python train.py --config exp3_simple.yaml

# Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ğ¾ÑĞ²ÑÑ‚ÑÑ Ğ² WandB Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ
```

---

## ğŸš€ Production Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹

### ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ production
```yaml
# config_production.yaml
data:
  val_split: 0.15  # Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ

training:
  epochs: 100
  batch_size: 64
  learning_rate: 0.0001

model:
  backbone_name: "ResNet50"
  dropout_rate: 0.5

early_stopping_patience: 15  # Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ Ñ‚ĞµÑ€Ğ¿ĞµĞ½Ğ¸Ñ
```

```bash
python train.py --config config_production.yaml
```

### Fine-tuning Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²ĞµÑĞ°Ğ¼Ğ¸
```yaml
# config_finetune.yaml
training:
  learning_rate: 0.00001  # ĞÑ‡ĞµĞ½ÑŒ Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ¸Ğ¹ LR
  epochs: 50

model:
  backbone_name: "ResNet50"
```

```bash
python train.py --pretrained --config config_finetune.yaml
```

---

## ğŸ§ª Debugging Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

### Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Ğ½Ğ° Ğ¼Ğ°Ğ»Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ
```yaml
# config_test.yaml
data:
  val_split: 0.5  # 50/50 split Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚Ğ°

training:
  epochs: 5
  batch_size: 16
```

```bash
python train.py --config config_test.yaml
```

### ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° overfitting
```yaml
# config_overfit_test.yaml
model:
  dropout_rate: 0.0  # Ğ‘ĞµĞ· dropout

training:
  epochs: 100
  
augmentation:
  flip_mode: "none"  # Ğ‘ĞµĞ· Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸
```

Ğ¦ĞµĞ»ÑŒ: Train accuracy Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ ÑÑ‚Ñ€ĞµĞ¼Ğ¸Ñ‚ÑŒÑÑ Ğº 100%, val Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½Ğ¸Ğ¶Ğµ

---

## ğŸ’¡ Best Practices

### 1. ĞĞ°Ñ‡Ğ½Ğ¸Ñ‚Ğµ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°
```bash
# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ SimpleCNN Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚Ğ°
python train.py --config config_simple.yaml
```

### 2. Ğ“Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ğ¾ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°Ğ¹Ñ‚Ğµ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ
```bash
# ĞŸĞ¾ÑĞ»Ğµ SimpleCNN -> MobileNet -> ResNet50
python train.py --config config_mobilenet.yaml
python train.py --config config_resnet.yaml
```

### 3. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ñ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸ĞµĞ¹
```bash
# Ğ•ÑĞ»Ğ¸ overfitting - ÑƒÑĞ¸Ğ»ÑŒÑ‚Ğµ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
# Ğ•ÑĞ»Ğ¸ underfitting - Ğ¾ÑĞ»Ğ°Ğ±ÑŒÑ‚Ğµ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
```

### 4. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ transfer learning ĞµÑĞ»Ğ¸ Ğ¼Ğ°Ğ»Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
```bash
python train.py --pretrained
```

### 5. ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€ÑŒÑ‚Ğµ Ñ‡ĞµÑ€ĞµĞ· WandB
- Ğ¡Ğ»ĞµĞ´Ğ¸Ñ‚Ğµ Ğ·Ğ° Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†ĞµĞ¹ train_loss Ğ¸ val_loss
- Ğ‘Ğ¾Ğ»ÑŒÑˆĞ°Ñ Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†Ğ° = overfitting
- ĞĞ±Ğµ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğµ = underfitting

---

## ğŸ¯ Ğ¦ĞµĞ»ĞµĞ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸

### ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
- Val Accuracy > 70%
- Train-Val gap < 15%

### Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- Val Accuracy > 85%
- Train-Val gap < 10%

### ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- Val Accuracy > 90%
- Train-Val gap < 5%

---

## ğŸ“ Troubleshooting

### Out of Memory
```yaml
training:
  batch_size: 8  # Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ñ‚Ğµ batch size
```

### ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ
```yaml
training:
  learning_rate: 0.01  # Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡ÑŒÑ‚Ğµ LR
```

### Overfitting
```yaml
model:
  dropout_rate: 0.7  # Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡ÑŒÑ‚Ğµ dropout

augmentation:
  rotation_factor: 0.2  # Ğ£ÑĞ¸Ğ»ÑŒÑ‚Ğµ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
```

### Underfitting
```yaml
model:
  backbone_name: "ResNet50"  # Ğ‘Ğ¾Ğ»ĞµĞµ Ğ¼Ğ¾Ñ‰Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
  dense_units: 512  # Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²

training:
  epochs: 100  # Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ ÑĞ¿Ğ¾Ñ…
```