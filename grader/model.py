"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏ —Å shared weights
"""
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import mixed_precision

def create_simple_cnn(input_shape):
    """
    –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç—É—é CNN –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –Ω—É–ª—è.
    –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º –º–æ–¥–µ–ª—è–º –¥–ª—è —É—á–µ–±–Ω—ã—Ö —Ü–µ–ª–µ–π.
    
    Args:
        input_shape (tuple): –§–æ—Ä–º–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (H, W, C)
        
    Returns:
        tf.keras.Model: CNN –º–æ–¥–µ–ª—å –±–µ–∑ fully-connected —Å–ª–æ–µ–≤
    """
    model = keras.Sequential([
        # Block 1
        layers.Input(shape=input_shape),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.BatchNormalization(),
        
        # Block 2
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.BatchNormalization(),
        
        # Block 3
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.BatchNormalization(),
        
        # Block 4
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.BatchNormalization(),
        
        # Block 5
        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.BatchNormalization(),
    ], name='SimpleCNN')
    
    return model


def create_backbone(backbone_name, input_shape, pretrained=False):
    """
    –°–æ–∑–¥–∞–µ—Ç backbone –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    
    Args:
        backbone_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã 
            ('ResNet50', 'ResNet50V2', 'MobileNetV2', 'EfficientNetB0', 
             'EfficientNetB3', 'DenseNet121', 'ConvNeXtTiny', 'SimpleCNN')
        input_shape (tuple): –§–æ—Ä–º–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (H, W, C)
        pretrained (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ (imagenet)
        
    Returns:
        tf.keras.Model: –ú–æ–¥–µ–ª—å-–±—ç–∫–±–æ–Ω
    """
    
    weights = 'imagenet' if pretrained else None
    
    if backbone_name == "ResNet50":
        backbone = keras.applications.ResNet50(
            weights=weights,
            include_top=False,
            input_shape=input_shape,
            pooling=None
        )
        
    elif backbone_name == "ResNet50V2":
        backbone = keras.applications.ResNet50V2(
            weights=weights,
            include_top=False,
            input_shape=input_shape,
            pooling=None
        )
        
    elif backbone_name == "MobileNetV2":
        backbone = keras.applications.MobileNetV2(
            weights=weights,
            include_top=False,
            input_shape=input_shape,
            pooling=None
        )
        
    elif backbone_name == "EfficientNetB0":
        backbone = keras.applications.EfficientNetB0(
            weights=weights,
            include_top=False,
            input_shape=input_shape,
            pooling=None
        )
        
    elif backbone_name == "EfficientNetB3":
        backbone = keras.applications.EfficientNetB3(
            weights=weights,
            include_top=False,
            input_shape=input_shape,
            pooling=None
        )
        
    elif backbone_name == "DenseNet121":
        backbone = keras.applications.DenseNet121(
            weights=weights,
            include_top=False,
            input_shape=input_shape,
            pooling=None
        )
        
    elif backbone_name == "ConvNeXtTiny":
        backbone = keras.applications.ConvNeXtTiny(
            weights=weights,
            include_top=False,
            input_shape=input_shape,
            pooling=None
        )

    elif backbone_name == "SimpleCNN":
        backbone = create_simple_cnn(input_shape)
        weights = None  # –î–ª—è –∫–∞—Å—Ç–æ–º–Ω–æ–π —Å–µ—Ç–∏
    else:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π backbone: {backbone_name}")
    
    print(f"‚úì –°–æ–∑–¥–∞–Ω backbone: {backbone_name} "
          f"({'–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞' if pretrained else '–æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è'})")
    
    return backbone

def create_augmentation_layer(config):
    aug_config = config['augmentation']
    layers = []

    if aug_config['flip_mode'] == 'horizontal':
        layers.append(tf.keras.layers.RandomFlip("horizontal"))
    elif aug_config['flip_mode'] == 'vertical':
        layers.append(tf.keras.layers.RandomFlip("vertical"))
    elif aug_config['flip_mode'] == 'horizontal_and_vertical':
        layers.append(tf.keras.layers.RandomFlip("horizontal_and_vertical"))
    
    if aug_config['rotation_factor'] > 0:
        layers.append(tf.keras.layers.RandomRotation(aug_config['rotation_factor']))
    
    if aug_config.get('zoom_factor', 0) > 0:
        layers.append(tf.keras.layers.RandomZoom(aug_config['zoom_factor']))
    
    if aug_config['brightness_factor'] > 0:
        layers.append(tf.keras.layers.RandomBrightness(aug_config['brightness_factor']))

    return tf.keras.Sequential(layers, name='augmentation')


def build_model(config):
    """
    –°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—É—é –º–æ–¥–µ–ª—å —Å –¥–≤—É–º—è –≤—Ö–æ–¥–∞–º–∏ –∏ shared weights
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    - –î–≤–∞ –≤—Ö–æ–¥–∞ (–∞–≤–µ—Ä—Å –∏ —Ä–µ–≤–µ—Ä—Å –º–æ–Ω–µ—Ç—ã)
    - –û–¥–∏–Ω –æ–±—â–∏–π –±—ç–∫–±–æ–Ω (shared weights) –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    - GlobalAveragePooling2D –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã—Ö–æ–¥–∞ –±—ç–∫–±–æ–Ω–∞
    - Concatenate –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏
    - Dense —Å–ª–æ–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    
    Args:
        config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        
    Returns:
        tf.keras.Model: –°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    """
    print("\n" + "="*50)
    print("–°–û–ó–î–ê–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("="*50)

    image_size = config['data']['image_size']
    num_classes = config['data']['num_classes']
    backbone_name = config['model']['backbone_name']
    dropout_rate = config['model']['dropout_rate']
    dense_units = config['model']['dense_units']

    mixed_precision.set_global_policy('mixed_float16')

    input_shape = (image_size, image_size, 3)
    
    # –°–æ–∑–¥–∞–µ–º –¥–≤–∞ –≤—Ö–æ–¥–∞
    input_obverse = keras.Input(shape=input_shape, name='input_obverse')
    input_reverse = keras.Input(shape=input_shape, name='input_reverse')
    
    # üîπ –°–æ–∑–¥–∞—ë–º —Å–ª–æ–π –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (–æ–Ω —Å–∞–º –∑–Ω–∞–µ—Ç –ø—Ä–æ training=True/False)
    augmentation = create_augmentation_layer(config)
    aug_obverse = augmentation(input_obverse)
    aug_reverse = augmentation(input_reverse)
    
    # –°–æ–∑–¥–∞–µ–º –û–î–ò–ù –±—ç–∫–±–æ–Ω (shared weights)
    backbone = create_backbone(backbone_name, input_shape) # try
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –±—ç–∫–±–æ–Ω –∫ –æ–±–æ–∏–º –≤—Ö–æ–¥–∞–º
    features_obverse = backbone(aug_obverse)
    features_reverse = backbone(aug_reverse)
    
    # Global Average Pooling –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã—Ö–æ–¥–∞
    pooled_obverse = layers.GlobalAveragePooling2D(name='gap_obverse')(features_obverse)
    pooled_reverse = layers.GlobalAveragePooling2D(name='gap_reverse')(features_reverse)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    combined = layers.Concatenate(name='concatenate')([pooled_obverse, pooled_reverse])
    
    # Classification head
    x = layers.Dense(dense_units, activation='relu', name='dense1')(combined)
    x = layers.Dropout(dropout_rate, name='dropout1')(x)
    
    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –µ—â–µ –æ–¥–∏–Ω Dense —Å–ª–æ–π –¥–ª—è –±–æ–ª—å—à–µ–π –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    x = layers.Dense(dense_units // 2, activation='relu', name='dense2')(x)
    x = layers.Dropout(dropout_rate / 2, name='dropout2')(x)
    
    # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
    outputs = layers.Dense(num_classes, activation='softmax', name='output', dtype='float32')(x)
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    model = keras.Model(
        inputs=[input_obverse, input_reverse],
        outputs=outputs,
        name='CoinGrader'
    )
    
    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è
    optimizer_name = config['training']['optimizer']
    learning_rate = config['training']['learning_rate']
    
    if optimizer_name == "Adam":
        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    elif optimizer_name == "RMSprop":
        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)
    elif optimizer_name == "SGD":
        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)
    else:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: {optimizer_name}")
    
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print(f"\n‚úì –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ –∏ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞")
    print(f"  –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: {optimizer_name}")
    print(f"  Learning Rate: {learning_rate}")
    print(f"  Dropout: {dropout_rate}")
    print("="*50 + "\n")
    
    return model


def build_model_with_pretrained(config, weights='imagenet'):
    """
    –í–∞—Ä–∏–∞–Ω—Ç –º–æ–¥–µ–ª–∏ —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ (–¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)
    
    Args:
        config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        weights (str): 'imagenet' –∏–ª–∏ None
        
    Returns:
        tf.keras.Model: –°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    """
    print("\n" + "="*50)
    print("–°–û–ó–î–ê–ù–ò–ï –ú–û–î–ï–õ–ò –° –ü–†–ï–î–û–ë–£–ß–ï–ù–ù–´–ú–ò –í–ï–°–ê–ú–ò")
    print("="*50)
    
    image_size = config['data']['image_size']
    num_classes = config['data']['num_classes']
    backbone_name = config['model']['backbone_name']
    dropout_rate = config['model']['dropout_rate']
    dense_units = config['model']['dense_units']
    
    input_shape = (image_size, image_size, 3)
    
    # –°–æ–∑–¥–∞–µ–º –¥–≤–∞ –≤—Ö–æ–¥–∞
    input_obverse = keras.Input(shape=input_shape, name='input_obverse')
    input_reverse = keras.Input(shape=input_shape, name='input_reverse')
    
    # –°–æ–∑–¥–∞–µ–º –±—ç–∫–±–æ–Ω —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
    if backbone_name == "ResNet50":
        backbone = keras.applications.ResNet50(
            weights=weights,
            include_top=False,
            input_shape=input_shape,
            pooling=None
        )
    elif backbone_name == "MobileNetV2":
        backbone = keras.applications.MobileNetV2(
            weights=weights,
            include_top=False,
            input_shape=input_shape,
            pooling=None
        )
    else:
        raise ValueError(f"–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –¥–æ—Å—Ç—É–ø–Ω—ã —Ç–æ–ª—å–∫–æ –¥–ª—è ResNet50 –∏ MobileNetV2")
    
    print(f"‚úì –°–æ–∑–¥–∞–Ω backbone: {backbone_name} —Å –≤–µ—Å–∞–º–∏ {weights}")
    
    # –ó–∞–º–æ—Ä–æ–∑–∫–∞ –Ω–∞—á–∞–ª—å–Ω—ã—Ö —Å–ª–æ–µ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    backbone.trainable = False  # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è fine-tuning
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –±—ç–∫–±–æ–Ω –∫ –æ–±–æ–∏–º –≤—Ö–æ–¥–∞–º
    features_obverse = backbone(input_obverse)
    features_reverse = backbone(input_reverse)
    
    # Global Average Pooling
    pooled_obverse = layers.GlobalAveragePooling2D()(features_obverse)
    pooled_reverse = layers.GlobalAveragePooling2D()(features_reverse)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º
    combined = layers.Concatenate()([pooled_obverse, pooled_reverse])
    
    # Classification head
    x = layers.Dense(dense_units, activation='relu')(combined)
    x = layers.Dropout(dropout_rate)(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)
    
    model = keras.Model(
        inputs=[input_obverse, input_reverse],
        outputs=outputs,
        name='CoinGrader_Pretrained'
    )
    
    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è
    optimizer = keras.optimizers.Adam(learning_rate=config['training']['learning_rate'])
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print(f"‚úì –ú–æ–¥–µ–ª—å —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ —Å–æ–∑–¥–∞–Ω–∞")
    print("="*50 + "\n")
    
    return model